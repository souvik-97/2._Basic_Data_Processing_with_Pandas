{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, will talk about one of the primary data types of the Pandas Library, the Series. You'll learn about the structure of the Series, how to query and emerge Series objects together, and the importance of thinking about parallelization when engaging in data science programming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A pandas Series can be queried either by the index position or the index label. If you don't give an index to the series when\n",
    "# querying, the position in the label are effectively the same values. To query by numeric location, starting at 0, use the\n",
    "# \"iloc\" attribute. To query by the index label, you can use the \"loc\" attribute. \n",
    "\n",
    "# So let's start with an example. We'll use students enrolled in classes coming from a dictionary:\n",
    "import pandas as pd\n",
    "students_classes = {'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'}\n",
    "s = pd.Series(students_classes)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, for this series, if you wanted to see the 4th entry, we could use the iloc attribute with the parameter 3:\n",
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you wanted to see what class Molly has, we would use the loc attribute with a parameter of Molly:\n",
    "s.loc['Molly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So keep in mind that iloc and loc are not methods, they are attributes, so you don't use parentheses to query them, but square\n",
    "# brackets instead, and this is called the indexing operator. In Python this calls get or set for an item depending on the\n",
    "# context of its use.\n",
    "# This might seem a bit confusing if you're used to languages where encapsulation of attributes, variables, and properties is\n",
    "# common, such as in Java.\n",
    "\n",
    "# Pandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator directly on\n",
    "# the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want to query via the\n",
    "# iloc attribute:\n",
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you pass in an object, it will query as if you wanted to use the label based on the loc attribute:\n",
    "s['Molly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what happens if your index is actually a list of integers? And this is a bit complicated and Pandas can't determine\n",
    "# automatically whether you're intending to query by index position or index label. So you need to be careful when you're using\n",
    "# the indexing operator on the Series itself. The safer option is to be more explicit and to use the iloc and loc attributes\n",
    "# directly.\n",
    "\n",
    "# Here's an example using classes in their classcode information, where classes are indexed by classcodes in the form of\n",
    "# integers. \n",
    "# So let's create some new dictionary classcode will say 99 maps to Physics, 100 to Chemistry, 101 to English, and 102 to\n",
    "# History, and will create some new series.\n",
    "class_code = {99: 'Physics',\n",
    "             100: 'Chemistry',\n",
    "             101: 'English',\n",
    "             102: 'History'}\n",
    "s = pd.Series(class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0bf512e1563b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# If we try and call, s[0] we get a key error because there's no item in the class list with an index of 0. Instead, we have to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# call iloc explicitly if we want the first item. So s sub zero, and that gives us this nasty looking key error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# If we try and call, s[0] we get a key error because there's no item in the class list with an index of 0. Instead, we have to\n",
    "# call iloc explicitly if we want the first item. So s sub zero, and that gives us this nasty looking key error.\n",
    "s[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, that didn't call s.iloc[0] underneath as one might expect, and instead it generated this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# Now we know how to get data out of this series, let's talk about working with the data. A common task is to want to consider\n",
    "# all of the values inside of a series and do some sort of operation. This could be trying to find a certain number, or\n",
    "# summarizing the data or transforming the data in some kind of way.\n",
    "\n",
    "# A typical programmatic approach to this would be to iterate over all of the items in the series, and invoke the operation one\n",
    "# is interested in. For instance, we could create a Series of integers representing student grades, and just try and get the\n",
    "# average grade:\n",
    "grades = pd.Series([90,80,70,60])\n",
    "\n",
    "total = 0\n",
    "for grade in grades:\n",
    "    total+=grade\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# So just a very simple averaging function, this works, but it's slow. Modern computers can do many tasks simultaneously,\n",
    "# especially, but not only tasks involving mathematics.\n",
    "\n",
    "# Pandas and the underlying NumPy support a number of methods for computation called vectorization. Vectorization in particular\n",
    "# works with most of the functions in the NumPy library, including the sum function.\n",
    "\n",
    "# So here's how we would really write the code using the NumPy sum method. First we need to import the NumPy module\n",
    "import numpy as np\n",
    "\n",
    "# Then we'll just call np.sum and pass in an iterable item. In this case, our pandas series. \n",
    "total = np.sum(grades)\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    509\n",
       "1     39\n",
       "2     99\n",
       "3    786\n",
       "4    456\n",
       "dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now both of the methods create the same value, but is one actually faster? The Jupyter Notebook has a magic function which can\n",
    "# help.\n",
    "\n",
    "# First let's create a big series of random numbers, and this is actually used a lot when demonstrating techniques with pandas,\n",
    "# so you should get used to seeing this:\n",
    "numbers = pd.Series(np.random.randint(0,1000,10000))\n",
    "\n",
    "# Now let's look at the top five items in this series to make sure they actually seem random, and we could do this with the\n",
    "# head() function:\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can actually verify the length of the series is correct using the len function\n",
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so now we're confident that we have a big series. The ipython interpreter has something called magic functions that\n",
    "# begin with a percentage sign. If we type this sign and hit the tab key, you can see a list of the available magic functions.\n",
    "# You could write your own magic functions too, but that's a little bit outside of the scope of this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So here we're actually going to use cellular magic function. These start with two percentage signs, an wrap the code in the\n",
    "# current Jupyter cell. The function we're going to use is called \"timeit\". This function will run our code a few times to\n",
    "# determine on average how long it takes. \n",
    "\n",
    "# So let's run timeit with our original iterative code. You can give timeit the number of loops that you would like to run. By\n",
    "# default it's 1,000 loops. I'll ask time it here to use 100 runs because we're recording this. Note that in order to use the\n",
    "# cellular magic function, it has to be the first line of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.36 ms ± 72.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = 0\n",
    "for number in numbers:\n",
    "    total += number\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All right, not bad, time it run the code and it doesn't seem to take very long at all. Now let's try with vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 µs ± 13 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = np.sum(numbers)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow, this is pretty shocking difference in the speed and demonstrates why one should be aware of parallel computing features\n",
    "# and start thinking in functional programming terms. Put more simply, vectorization is the ability for a computer to execute\n",
    "# multiple instructions at once. With high performance chips, especially graphics cards, you can get dynamic speedups. Modern\n",
    "# graphics cards can run thousands of instructions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    509\n",
       "1     39\n",
       "2     99\n",
       "3    786\n",
       "4    456\n",
       "dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A related feature in pandas and NumPy is called \"broadcasting\". With broadcasting, we can apply an operation to every value\n",
    "# in the series, changing the series. For instance, if we wanted to increase every random variable by 2, we could do so quickly\n",
    "# using the += operator directly on the series object.\n",
    "\n",
    "# Let's look at the head of our series:\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    511\n",
       "1     41\n",
       "2    101\n",
       "3    788\n",
       "4    458\n",
       "dtype: int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now let's just increase everything in the series by 2\n",
    "# so s plus equals 2. So here we're applying the plus equals operator directly to the series object, not a single value. And now let's look at the head.\n",
    "numbers+=2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    513\n",
       "1     43\n",
       "2    103\n",
       "3    790\n",
       "4    460\n",
       "dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. Pandas does support iterating through the series much like a dictionary, allowing you to unpack values easily.\n",
    "\n",
    "# We can use the iteritems() function in particular which returns a label and value:\n",
    "# So for label and value in s.iteritems, now for the item which is returned, let's call the set value. So s.set_value, we indicate the label, and we say the value we just want to increment that by 2. \n",
    "\n",
    "for label, value in numbers.iteritems():\n",
    "    # Now for the item which is returned, let's call the set value()\n",
    "    numbers.at[label] = value+2\n",
    "# And then let's check the result of the This for loop computation by looking at the head.\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the result is the same, though you may notice a warning depending on the version of Pandas being used. But if you find yourself iterating pretty much anytime in Pandas, you should question whether you're doing things in the best possible way.\n",
    "\n",
    "# Let's take a look at some speed comparisons. First, let's try five loops using the iterative approach:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 ms ± 3.84 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "#We'll create a blank new series of items to deal with. Always good when timing to create a new series\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we'll just rewrite our loop from above:\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try using that broadcasting method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 µs ± 134 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# We need to recreate the series:\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we just broadcast  with +=\n",
    "s+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "History    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amazing. Not only is it significantly faster, but it's more concise, an even easier to read too. The typical mathematical operations that you would expect are vectorized, and the NumPy documentation outlines what it would take to create vectorized functions of your own.\n",
    "\n",
    "# One last note on using the indexing operators to access series data. The .loc attribute lets you not only modify data in place, but also add new data as well. If the value you passed in as the index doesn't exist, then a new entry is created. And keep in mind indices can have mixed types. While it's important to be aware of the typing going on underneath, Pandas will automatically change the underlying NumPy types as appropriate.\n",
    "\n",
    "# Here's an example using a series of a few numbers;\n",
    "s = pd.Series([1,2,3])\n",
    "# We could add some new value, maybe a university course:\n",
    "s.loc['History'] = 102\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that mixed types for data values or index labels are no problem for Pandas. Since \"History\" is not in the original list of indices, s.loc['History'] essentially creates a new element in the series, with the index name of 'History', and the value of 102.\n",
    "\n",
    "# Up until now, I've shown only examples of a series where the index values were unique. I want to end this lecture by showing an example where index values are not unique. And this makes the Pandas Series a little different conceptually than, for instance, a relational database.\n",
    "\n",
    "# Let's create a series with students and courses which they have taken:\n",
    "students_classes = pd.Series({'Alice': 'Physics',\n",
    "                            'Jack': 'Chemistry',\n",
    "                            'Molly': 'English',\n",
    "                            'Sam': 'History'})\n",
    "student_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's create a series just for some new student, Kelly, which lists all of the courses that she's taken. We'll set the index to Kelly, and the data to be the names of the courses:\n",
    "kelly_classes = pd.Series(['Philosophy','Arts','Math'], index=['Kelly','Kelly','Kelly'])\n",
    "kelly_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice       Physics\n",
       "Jack      Chemistry\n",
       "Molly       English\n",
       "Sam         History\n",
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we can append all of the data in this Series to the .append() function.\n",
    "all_students_classes = students_classes.append(kelly_classes)\n",
    "\n",
    "# This creates a series which has our original people in it as well as all of Kelly's courses:\n",
    "all_students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are a couple of important considerations when using .append. First, Pandas will take the series and try to infer the best data types to use. In this example, everything is a string, so there's no problems here. Second, the append method doesn't actually change the underlying Series objects. It instead returns a new series which is made up of the two appended together. And this is actually a common pattern in Pandas. By default, returning a new object instead of modifying one in place. And one that you should come to expect. By printing the original series, we can see that that series hasn't changed:\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we can see that when we query the appended series for Kelly, we don't get a single value, but a series itself:\n",
    "all_students_classes.loc['Kelly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we focused on one of the primary data types of the Pandas Libra. The series you learn how to query the series with lock and I lock that the series is an index data structure. How to merge two series objects together with append an the importance of vectorization. \n",
    "\n",
    "There are many more methods associated with the series object that we haven't talked about, but with these basics down will move on to talking about pandas, 2 dimensional data structure, the data frame. The data frame is very similar to the series object, but includes multiple columns of data. Is the structure you'll spend the majority of your time working on when cleaning and aggregating data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
